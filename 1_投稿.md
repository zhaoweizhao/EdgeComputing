# Energy-efficient Image Classification on Edge Devices

## Abstract
DNN模型，例如ViT，CNN，在计算机视觉任务中取得了巨大的成功。然而，将大型且计算密集的DNN模型直接部署在资源受限的边缘设备上，会导致难以忍受的能耗和时延问题。
为了解决这个问题，我们提出一个名为GFDE(GFNet,Distil,Early Exit)的新颖框架，该框架通过降低DNN模型的参数量，并允许样本提前退出，从而在边缘端实现了高效节能的图片分类。
具体来说，我们首先通过知识蒸馏对DNN模型进行轻量化，再对蒸馏后的模型加入早退分支，早退分支确定输入样本从哪里退出。此外，在模型推理的时候，我们将早退分支的参数加载到CPU上，
其他参数一律加载到GPU上，实现了简单的异构计算。大量实验结果表明，与经典的深度学习网络相比，我们所提出的框架实现了高达64.74%的能耗降低率和38.87%的时延降低率，同时保证精度损失在3%以内。

## OVERVIEW AND PROBLEM STATEMENT
为了实现latency-efficient和energy-efficienct的inference，我们提出了GFDE框架，该框架利用GFNet作为backbone，同时我们利用DeiT的全局蒸馏思想
对GFNet进行知识蒸馏。最后我们为蒸馏后的模型加入早退分支模块，可以通过辨别样本的复杂度来选择退出点。图1展示了GFDE的总体流程算法。图2展示了GFDE的总体框架图。

1、针对指定数据集，对原始的、大的GFNet模型进行迁移学习。
2、对原始的、大的GFNet进行知识蒸馏，得到较小、轻量化的模型。
3、为蒸馏后的模型加入早退分支。
4、在做模型推理时，将早退分支的参数加载到CPU吗，其他参数加载到GPU上。

## METHOD
