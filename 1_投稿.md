# Energy-efficient Image Classification on Edge Devices

## Abstract
DNN模型，例如ViT，CNN，在计算机视觉任务中取得了巨大的成功。然而，将大型且计算密集的DNN模型直接部署在资源受限的边缘设备上，会导致难以忍受的能耗和时延问题。
为了解决这个问题，我们提出一个名为GFDE(GFNet,Distil,Early Exit)的新颖框架，该框架通过降低DNN模型的参数量，并允许样本提前退出，从而在边缘端实现了高效节能的图片分类。
具体来说，我们首先通过知识蒸馏对DNN模型进行轻量化，再对蒸馏后的模型加入早退分支，早退分支确定输入样本从哪里退出。此外，在模型推理的时候，我们将早退分支的参数加载到CPU上，
其他参数一律加载到GPU上，实现了简单的异构计算。大量实验结果表明，与经典的深度学习网络相比，我们所提出的框架实现了高达64.74%的能耗降低率和38.87%的时延降低率，同时保证精度损失在3%以内。

## OVERVIEW AND PROBLEM STATEMENT
为了实现latency-efficient和energy-efficienct的inference，我们提出了GFDE框架，图1展示了GFDE的总体流程算法。该框架利用GFNet作为backbone，同时我们利用DeiT的全局蒸馏思想对GFNet进行知识蒸馏。
最后我们为蒸馏后的模型加入以模型不确定性为基础的早退分支模块，可以通过辨别样本的复杂度来选择退出点。总的来说，我们通过降低模型的参数量和允许样本提前退出来实现边缘图片分析的实时性和高性能。图2展示了GFDE的总体框架图。

1、针对指定数据集，对原始的、大的GFNet模型进行迁移学习。

2、利用DeiT里的全局蒸馏思想对原始的、大的GFNet进行知识蒸馏，得到较小、轻量化的模型。

3、为蒸馏后的模型加入早退分支(EEB,Early Exit Branchy)。

4、在做模型推理时，将早退分支的参数加载到CPU吗，其他参数加载到GPU上。

GFNet是什么？

GFNet是一个概念简单但计算效率高的视觉识别架构，大量实验表明GFNet在效率、泛化能力和鲁棒性方面可以成为Vit和CNN的一个非常有竞争力的替代方案，同时GFNet能够以nlogn复杂度学习频域中的长期空间依赖性，故本文选择GFNet作为模型的backbone。GFNet主要由三个关键操作构成：二维离散傅立叶变换、频域特征与可学习全局滤波器之间的逐元素乘法操作、以及二维逆傅立叶变换。Global Filter Layer以对log-linear复杂度混合tokens，受益于高效的快速傅里叶变换(FFT)算法。GFNet由多个GFNet Blocks堆叠组成，每个GFNet Block又由Global Filter Layers 和 Feedforward Networks (FFN)堆叠而成，GFNet Block的网络结构由下图展示：

![image](https://github.com/user-attachments/assets/5a3a6810-36e1-455d-914b-5c27ae5c1989)

知识蒸馏？

知识蒸馏（Knowledge Distillation）是一种模型训练的技术，旨在通过传递一个大型教师模型的知识来训练一个小型学生模型。这个方法的目标是使得学生模型能够获得与教师模型相似的性能，同时减少学生模型的参数量和计算成本。我们从Deit中汲取灵感，利用DeiT里的全局蒸馏思想对我们的GFNet模型做知识蒸馏，从而实现在参数较少的情况下实现高效的图像分类。类似DeiT，我们也额外引入了一个Distillation token，同样，Distillation token类似于Class token，它通过Global Filter与其他embeddings进行交互，并由网络在最后一层之后输出，在网络输出时，其目标是重现教师预测的（硬）标签，而不是真实标签。我们首先预训练出一个大型的、精度高的GFNet模型，利用这个模型作为教师模型，本文采用DeiT的hard-label distillation，将教师模型的hard decision作为true label。GFNet的蒸馏操作将在第 METHOD-B 节中介绍。

![image](https://github.com/user-attachments/assets/73ee700c-b774-4282-8f50-3133579376a2)

为蒸馏后的模型加入早退分支

最后，我们为整个主干网络的某些位置插入我们所设计的早退分支，以便允许可以被网络浅层部分自信分类的样本提前从相应的分支退出[ 33]。早退分支中包含了门控机制（gate module），gate module根据此时的样本特征来确定是否有足够的信心
选择退出，其中我们利用模型的不确定性统计作为gate module的输入。早退分支(EEB,Early Exit Branchy)的详细结构和操作将在第 METHOD-C 节中介绍。

## METHOD
