```python
DYNN:avg=28.386284597873686ms
Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   236                                               @profile
   237                                               def forward(self, x):
   238     10100      63182.2      6.3      0.0          B = x.shape[0]
   239     10100       8432.6      0.8      0.0          n_blocks = 12
   240                                                   # print("B:",B)
   241     10100    4653593.2    460.8      1.8          x = self.patch_embed(x)
   242     10100     401628.5     39.8      0.2          cls_tokens = self.cls_token.expand(B, -1, -1)  # stole cls_tokens impl from Phil Wang, thanks
   243     10100     294340.6     29.1      0.1          dist_token = self.dist_token.expand(B, -1, -1)
   244     10100     974876.3     96.5      0.4          x = torch.cat((cls_tokens, dist_token, x), dim=1)
   245                                                   # print("X",x.shape)
   246                                                   # print("pos_embed",self.pos_embed.shape)
   247     10100     785276.7     77.8      0.3          x = x + self.pos_embed
   248     10100     598704.2     59.3      0.2          x = self.pos_drop(x)
   249
   250    113256     410562.2      3.6      0.2          for blk_idx, blk in enumerate(self.blocks):
   251    107266  148163388.1   1381.3     56.2              x = blk.forward(x)
   252    107266     206865.6      1.9      0.1              if blk_idx < 11 and blk_idx > 4:
   253     50776    6025846.1    118.7      2.3                  inter_z = self.norm(x)
   254                                                           # inter_logit = (self.intermediate_heads[blk_idx](inter_z[:, 0]) + self.intermediate_heads_dist[blk_idx](inter_z[:, 1])) / 2
   255     50776   10397619.4    204.8      3.9                  inter_logit = self.intermediate_heads[blk_idx](inter_z[:, 0])
   256                                                           # probs = torch.nn.functional.softmax(inter_logit, dim=1)
   257                                                           # print(probs)
   258                                                           # pred, _ = probs.topk(1, 1, True, False)
   259                                                           # print(pred)
   260     50776   78458972.8   1545.2     29.8                  g =self.gates[blk_idx](inter_logit)
   261     50776    3234124.2     63.7      1.2                  g = torch.nn.functional.sigmoid(g)
   262                                                           # print(g)
   263     50776    6948321.7    136.8      2.6                  if g >= self.threshold:
   264                                                               # print(blk_idx)
   265      4110      12385.3      3.0      0.0                      return inter_logit, blk_idx
   266
   267      5990     704235.6    117.6      0.3          x = self.norm(x)
   268                                                   # x = (self.head(x[:, 0]) + self.head_dist(x[:, 1])) / 2
   269      5990    1092973.8    182.5      0.4          x = self.head(x[:, 0])
   270      5990       7655.7      1.3      0.0          return x, blk_idx
```
