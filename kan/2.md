```python
DYNN:avg=26.8611168255806ms
Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   236                                               @profile
   237                                               def forward(self, x):
   238     10100      63182.2      6.3      0.0          B = x.shape[0]
   239     10100       8432.6      0.8      0.0          n_blocks = 12
   240                                                   # print("B:",B)
   241     10100    4653593.2    460.8      1.8          x = self.patch_embed(x)
   242     10100     401628.5     39.8      0.2          cls_tokens = self.cls_token.expand(B, -1, -1)  # stole cls_tokens impl from Phil Wang, thanks
   243     10100     294340.6     29.1      0.1          dist_token = self.dist_token.expand(B, -1, -1)
   244     10100     974876.3     96.5      0.4          x = torch.cat((cls_tokens, dist_token, x), dim=1)
   245                                                   # print("X",x.shape)
   246                                                   # print("pos_embed",self.pos_embed.shape)
   247     10100     785276.7     77.8      0.3          x = x + self.pos_embed
   248     10100     598704.2     59.3      0.2          x = self.pos_drop(x)
   249
   250    113256     410562.2      3.6      0.2          for blk_idx, blk in enumerate(self.blocks):
   251    107266  148163388.1   1381.3     56.2              x = blk.forward(x)
   252    107266     206865.6      1.9      0.1              if blk_idx < 11 and blk_idx > 4:
   253     50776    6025846.1    118.7      2.3                  inter_z = self.norm(x)
   254                                                           # inter_logit = (self.intermediate_heads[blk_idx](inter_z[:, 0]) + self.intermediate_heads_dist[blk_idx](inter_z[:, 1])) / 2
   255     50776   10397619.4    204.8      3.9                  inter_logit = self.intermediate_heads[blk_idx](inter_z[:, 0])
   256                                                           # probs = torch.nn.functional.softmax(inter_logit, dim=1)
   257                                                           # print(probs)
   258                                                           # pred, _ = probs.topk(1, 1, True, False)
   259                                                           # print(pred)
   260     50776   78458972.8   1545.2     29.8                  g =self.gates[blk_idx](inter_logit)
   261     50776    3234124.2     63.7      1.2                  g = torch.nn.functional.sigmoid(g)
   262                                                           # print(g)
   263     50776    6948321.7    136.8      2.6                  if g >= self.threshold:
   264                                                               # print(blk_idx)
   265      4110      12385.3      3.0      0.0                      return inter_logit, blk_idx
   266
   267      5990     704235.6    117.6      0.3          x = self.norm(x)
   268                                                   # x = (self.head(x[:, 0]) + self.head_dist(x[:, 1])) / 2
   269      5990    1092973.8    182.5      0.4          x = self.head(x[:, 0])
   270      5990       7655.7      1.3      0.0          return x, blk_idx

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    14                                               @profile
    15                                               def forward(self, logits: Tensor) -> (Tensor):
    16                                                   # p_maxes, entropies, _, margins, entropy_pows = compute_detached_uncertainty_metrics(logits, None)
    17     50787    3504727.0     69.0      5.3          probs = torch.nn.functional.softmax(logits, dim=1)
    18
    19     50787    5247954.3    103.3      7.9          top2prob, _ = torch.topk(probs, 2)
    20     50787    2347254.5     46.2      3.5          p_max = top2prob[:,0]
    21     50787    1794068.7     35.3      2.7          next_p_max = top2prob[:,1]
    22     50787    2695068.7     53.1      4.1          margins = p_max-next_p_max
    23
    24     50787   13711188.9    270.0     20.7          entropy = -torch.sum(probs * torch.log(probs + 1e-10), dim=1)
    25
    26
    27     50787    3413371.6     67.2      5.1          pow_probs = probs**2
    28     50787    5553630.9    109.4      8.4          pow_probs = pow_probs / pow_probs.sum(dim=1, keepdim=True)
    29     50787   12645269.6    249.0     19.0          entropy_pow = -torch.sum(pow_probs * torch.log(pow_probs + 1e-10), dim=1)
    30                                                   # print(entropy_pow)
    31
    32     50787    1023799.2     20.2      1.5          p_maxes = p_max.unsqueeze(1)
    33     50787     661463.5     13.0      1.0          entropies = entropy.unsqueeze(1)
    34     50787     605378.1     11.9      0.9          margins = margins.unsqueeze(1)
    35     50787     572908.5     11.3      0.9          entropy_pows = entropy_pow.unsqueeze(1)
    36     50787    3453328.7     68.0      5.2          uncertainty_metrics = torch.cat((p_maxes, entropies, margins, entropy_pows), dim = 1)
    37     50787    9153319.2    180.2     13.8          return self.linear(uncertainty_metrics.to(logits.device, dtype=logits.dtype))
```
```python
Epoch:5 || acc_layer0_val:28.24
Epoch:5 || acc_layer1_val:36.74
Epoch:5 || acc_layer2_val:40.52
Epoch:5 || acc_layer3_val:43.94
Epoch:5 || acc_layer4_val:44.82
Epoch:5 || acc_layer5_val:60.919999999999995
Epoch:5 || acc_layer6_val:67.13
Epoch:5 || acc_layer7_val:72.83
Epoch:5 || acc_layer8_val:80.67999999999999
Epoch:5 || acc_layer9_val:89.97
Epoch:5 || acc_layer10_val:93.33
Epoch:5 || acc_layer11_val:97.1

****************0.5****************
Exiting Layer0:[0.0/0]
Exiting Layer1:[0.0/0]
Exiting Layer2:[0.0/0]
Exiting Layer3:[0.0/0]
Exiting Layer4:[0.0/0]
Exiting Layer5:[3.569999933242798/98.03921508789062]
Exiting Layer6:[10.920000076293945/97.9853515625]
Exiting Layer7:[10.1899995803833/98.9205093383789]
Exiting Layer8:[18.8700008392334/96.87334442138672]
Exiting Layer9:[23.540000915527344/98.55564880371094]
Exiting Layer10:[16.020000457763672/95.1935043334961]
Exiting Layer11:[16.889999389648438/88.92835998535156]
acc_val=96.03,total_GFLOPs=108.13236236572266G

[0, 0, 0, 0, 0, 0, 0, 2396, 1931, 0, 0, 5673]
* Acc@1 96.500 Acc@5 99.930 loss 0.139

[0, 0, 0, 0, 0, 0, 0, 2396, 0, 4216, 1666, 1722]
* Acc@1 96.460 Acc@5 99.890 loss 0.153
```

## GPU inference
```python
==> Building model..
using linear droppath with expect rate 0.0
Model was successfully measured and exit costs were assigned [63024656.96933601, 68246561.93867202, 73468466.90800802, 78690371.87734403, 83912276.84668003, 89134181.81601603, 94356086.78535204, 99577991.75468804, 104799896.72402404, 110021801.69336005, 115243706.66269605, 120560555.63203205]
[63.024654388427734, 68.2465591430664, 73.46846771240234, 78.69036865234375, 83.91227722167969, 89.13418579101562, 94.35608673095703, 99.57799530029297, 104.79989624023438, 110.02179718017578, 115.24370574951172, 120.56055450439453]
########################################
==> Resuming from checkpoint..
Missing keys: []
Unexpected keys: []
Unfreezing classifiers after warmup
warm up ...

testing ...

100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [04:22<00:00, 38.16it/s]

avg=21.665121528339387

Wrote profile results to tttttt.py.lprof
Timer unit: 1e-06 s

Total time: 28.454 s
File: /home/nvidia/heShaoWei/GFNet/dynn/gate/learnable_uncertainty_gate.py
Function: forward at line 14

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    14                                               @profile
    15                                               def forward(self, logits: Tensor) -> (Tensor):
    16                                                   # p_maxes, entropies, _, margins, entropy_pows = compute_detached_uncertainty_metrics(logits, None)
    17     21301    1516597.4     71.2      5.3          probs = torch.nn.functional.softmax(logits, dim=1)
    18
    19     21301    2312922.8    108.6      8.1          top2prob, _ = torch.topk(probs, 2)
    20     21301     953426.4     44.8      3.4          p_max = top2prob[:,0]
    21     21301     749632.1     35.2      2.6          next_p_max = top2prob[:,1]
    22     21301    1134164.1     53.2      4.0          margins = p_max-next_p_max
    23
    24     21301    5922956.2    278.1     20.8          entropy = -torch.sum(probs * torch.log(probs + 1e-10), dim=1)
    25
    26
    27     21301    1521970.7     71.5      5.3          pow_probs = probs**2
    28     21301    2347307.2    110.2      8.2          pow_probs = pow_probs / pow_probs.sum(dim=1, keepdim=True)
    29     21301    5317696.1    249.6     18.7          entropy_pow = -torch.sum(pow_probs * torch.log(pow_probs + 1e-10), dim=1)
    30                                                   # print(entropy_pow)
    31
    32     21301     475331.1     22.3      1.7          p_maxes = p_max.unsqueeze(1)
    33     21301     281294.3     13.2      1.0          entropies = entropy.unsqueeze(1)
    34     21301     256269.0     12.0      0.9          margins = margins.unsqueeze(1)
    35     21301     244559.9     11.5      0.9          entropy_pows = entropy_pow.unsqueeze(1)
    36     21301    1486399.5     69.8      5.2          uncertainty_metrics = torch.cat((p_maxes, entropies, margins, entropy_pows), dim = 1)
    37     21301    3933507.9    184.7     13.8          return self.linear(uncertainty_metrics.to(logits.device, dtype=logits.dtype))

Total time: 196.52 s
File: /home/nvidia/heShaoWei/GFNet/dynn/gfnet_dynn.py
Function: forward at line 236

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   236                                               @profile
   237                                               def forward(self, x):
   238     10100      61977.8      6.1      0.0          B = x.shape[0]
   239     10100       6632.9      0.7      0.0          n_blocks = 12
   240                                                   # print("B:",B)
   241     10100    4561913.1    451.7      2.3          x = self.patch_embed(x)
   242     10100     396567.4     39.3      0.2          cls_tokens = self.cls_token.expand(B, -1, -1)  # stole cls_tokens impl from Phil Wang, thanks
   243     10100     276350.2     27.4      0.1          dist_token = self.dist_token.expand(B, -1, -1)
   244     10100     956094.3     94.7      0.5          x = torch.cat((cls_tokens, dist_token, x), dim=1)
   245                                                   # print("X",x.shape)
   246                                                   # print("pos_embed",self.pos_embed.shape)
   247     10100     779426.7     77.2      0.4          x = x + self.pos_embed
   248     10100     617101.4     61.1      0.3          x = self.pos_drop(x)
   249
   250    103337     345610.8      3.3      0.2          for blk_idx, blk in enumerate(self.blocks):
   251    101515  135091257.2   1330.8     68.7              x = blk.forward(x)
   252    101515     229776.9      2.3      0.1              if blk_idx == 7 or blk_idx == 9 or blk_idx == 10:
   253     21290    2539369.9    119.3      1.3                  inter_z = self.norm(x)
   254     21290   10841899.3    509.2      5.5                  inter_logit = (self.intermediate_heads[blk_idx](inter_z[:, 0]) + self.intermediate_heads_dist[blk_idx](inter_z[:, 1])) / 2
   255                                                           # inter_logit = self.intermediate_heads[blk_idx](inter_z[:, 0])
   256                                                           # probs = torch.nn.functional.softmax(inter_logit, dim=1)
   257                                                           # print(probs)
   258                                                           # pred, _ = probs.topk(1, 1, True, False)
   259                                                           # print(pred)
   260     21290   34367400.9   1614.3     17.5                  g =self.gates[blk_idx](inter_logit)
   261     21290    1358073.9     63.8      0.7                  g = torch.nn.functional.sigmoid(g)
   262                                                           # print(g)
   263     21290    3001698.0    141.0      1.5                  if g >= self.threshold:
   264                                                               # print(blk_idx)
   265      8278      24635.8      3.0      0.0                      return inter_logit, blk_idx
   266
   267      1822     214554.8    117.8      0.1          x = self.norm(x)
   268      1822     847340.1    465.1      0.4          x = (self.head(x[:, 0]) + self.head_dist(x[:, 1])) / 2
   269                                                   # x = self.head(x[:, 0])
   270      1822       2432.9      1.3      0.0          return x, blk_idx
```

## CPU inference
```python
==> Building model..
using linear droppath with expect rate 0.0
Model was successfully measured and exit costs were assigned [63024656.96933601, 68246561.93867202, 73468466.90800802, 78690371.87734403, 83912276.84668003, 89134181.81601603, 94356086.78535204, 99577991.75468804, 104799896.72402404, 110021801.69336005, 115243706.66269605, 120560555.63203205]
[63.024654388427734, 68.2465591430664, 73.46846771240234, 78.69036865234375, 83.91227722167969, 89.13418579101562, 94.35608673095703, 99.57799530029297, 104.79989624023438, 110.02179718017578, 115.24370574951172, 120.56055450439453]
==> Resuming from checkpoint..
Missing keys: []
Unexpected keys: []
Unfreezing classifiers after warmup
warm up ...

testing ...

100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [09:19<00:00, 17.88it/s]

avg=50.70435286102295

Wrote profile results to tttttt.py.lprof
Timer unit: 1e-06 s

Total time: 13.9223 s
File: /home/nvidia/heShaoWei/GFNet/dynn/gate/learnable_uncertainty_gate.py
Function: forward at line 39

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    39                                               @profile
    40                                               def forward(self, logits: Tensor) -> Tensor:
    41                                                   # 使用log_softmax来进一步优化计算熵的效率
    42     21301    1222129.0     57.4      8.8          log_probs = torch.nn.functional.log_softmax(logits, dim=1)
    43     21301     710893.8     33.4      5.1          probs = torch.exp(log_probs)  # 等效于原来的 softmax
    44
    45                                                   # 优化top2概率的提取，避免冗余计算
    46     21301    1117765.6     52.5      8.0          top2probs, top2indices = torch.topk(probs, 2, dim=1)
    47     21301    1170012.0     54.9      8.4          p_max, next_p_max = top2probs[:, 0], top2probs[:, 1]
    48
    49                                                   # 计算margins
    50     21301     553559.1     26.0      4.0          margins = p_max - next_p_max
    51
    52                                               # 直接利用log_probs计算熵，避免重新计算log(probs)
    53     21301    1928784.2     90.5     13.9          entropy = -torch.sum(probs * log_probs, dim=1)
    54
    55                                               # 优化幂概率计算
    56     21301    1619176.8     76.0     11.6          pow_probs = torch.nn.functional.softmax(logits * 2, dim=1)  # 优化计算方式，直接调整logits
    57     21301    1157083.7     54.3      8.3          log_pow_probs = torch.nn.functional.log_softmax(logits * 2, dim=1)  # 直接使用log_softmax
    58     21301    1041384.6     48.9      7.5          entropy_pow = -torch.sum(pow_probs * log_pow_probs, dim=1)  # 利用幂概率的log版本
    59
    60                                                   # 合并概率矩阵，无需单独添加维度
    61     21301    1331583.8     62.5      9.6          uncertainty_metrics = torch.stack([p_max, entropy, margins, entropy_pow], dim=1)
    62
    63                                               # 将结果移至适当设备并调整类型，以便与logits兼容
    64     21301    2069939.5     97.2     14.9          return self.linear(uncertainty_metrics.to(device=logits.device, dtype=logits.dtype))

Total time: 509.035 s
File: /home/nvidia/heShaoWei/GFNet/dynn/gfnet_dynn.py
Function: forward at line 236

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   236                                               @profile
   237                                               def forward(self, x):
   238     10100      69307.5      6.9      0.0          B = x.shape[0]
   239     10100      13855.4      1.4      0.0          n_blocks = 12
   240                                                   # print("B:",B)
   241     10100   12956310.8   1282.8      2.5          x = self.patch_embed(x)
   242     10100     492046.0     48.7      0.1          cls_tokens = self.cls_token.expand(B, -1, -1)  # stole cls_tokens impl from Phil Wang, thanks
   243     10100     262424.1     26.0      0.1          dist_token = self.dist_token.expand(B, -1, -1)
   244     10100    2347496.9    232.4      0.5          x = torch.cat((cls_tokens, dist_token, x), dim=1)
   245                                                   # print("X",x.shape)
   246                                                   # print("pos_embed",self.pos_embed.shape)
   247     10100    1588208.2    157.2      0.3          x = x + self.pos_embed
   248     10100     760842.0     75.3      0.1          x = self.pos_drop(x)
   249
   250    103337     490333.1      4.7      0.1          for blk_idx, blk in enumerate(self.blocks):
   251    101515  450726789.7   4440.0     88.5              x = blk.forward(x)
   252    101515     153594.2      1.5      0.0              if blk_idx == 7 or blk_idx == 9 or blk_idx == 10:
   253     21290    4909733.9    230.6      1.0                  inter_z = self.norm(x)
   254     21290    9640239.8    452.8      1.9                  inter_logit = (self.intermediate_heads[blk_idx](inter_z[:, 0]) + self.intermediate_heads_dist[blk_idx](inter_z[:, 1])) / 2
   255                                                           # inter_logit = self.intermediate_heads[blk_idx](inter_z[:, 0])
   256                                                           # probs = torch.nn.functional.softmax(inter_logit, dim=1)
   257                                                           # print(probs)
   258                                                           # pred, _ = probs.topk(1, 1, True, False)
   259                                                           # print(pred)
   260     21290   21361157.8   1003.3      4.2                  g =self.gates[blk_idx](inter_logit)
   261     21290     711317.9     33.4      0.1                  g = torch.nn.functional.sigmoid(g)
   262                                                           # print(g)
   263     21290    1431873.8     67.3      0.3                  if g >= self.threshold:
   264                                                               # print(blk_idx)
   265      8278      24067.3      2.9      0.0                      return inter_logit, blk_idx
   266
   267      1822     413280.2    226.8      0.1          x = self.norm(x)
   268      1822     679918.5    373.2      0.1          x = (self.head(x[:, 0]) + self.head_dist(x[:, 1])) / 2
   269                                                   # x = self.head(x[:, 0])
   270      1822       1996.8      1.1      0.0          return x, blk_idx

Total time: 446.397 s
File: /home/nvidia/heShaoWei/GFNet/gfnet.py
Function: forward at line 95

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    95                                               @profile
    96                                               def forward(self, x):
    97    101527   22991464.8    226.5      5.2          x1 = self.norm1(x)
    98    101527  136526387.7   1344.7     30.6          x1 = self.filter(x1)
    99    101527   25061081.4    246.8      5.6          x1 = self.norm2(x1)
   100    101527  245660800.7   2419.7     55.0          x1 = self.mlp(x1)
   101    101527   16050406.8    158.1      3.6          x = x + self.drop_path(x1)
   102    101527     106938.6      1.1      0.0          return x
####################################################################################################
CPU:
   distilled:54.5ms
         * Acc@1 97.10
   distilled+dynn:51.0ms
         [0, 0, 0, 0, 0, 0, 0, 2396, 0, 4216, 1666, 1722]
         * Acc@1 96.46 Acc@5 99.89 loss 0.153
```
16011hsw*
## RT-DETR
```javascript
RT-DETR: 
  backbone: PResNet
  encoder: HybridEncoder
  decoder: RTDETRTransformer
  multi_scale: [480, 512, 544, 576, 608, 640, 640, 640, 672, 704, 736, 768, 800]
  DataSet: VisDrone2019-DET

IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.314
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.519
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.315
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.216
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.435
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.664
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.122
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.351
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.459
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.366
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.588
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.783
best_stat:  {'epoch': 170, 'coco_eval_bbox': 0.3136645166814497}
```
